{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ALPHAFOLD RESULTS TO FEATURES TO INPUT TO GNN"
      ],
      "metadata": {
        "id": "2isFUkbFXbyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9ZtXAMbd4nN",
        "outputId": "b9b42e73-5808-402b-8048-9108578485ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n"
      ],
      "metadata": {
        "id": "EFPZTz2oeQmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "\n",
        "directory = '/content/drive/MyDrive/alphafold_results'\n",
        " \n",
        "# iterate over files in that directory\n",
        "files = Path(directory).glob('*')\n",
        "for file in files:\n",
        "    # opening the zip file in READ mode\n",
        "    with ZipFile(file, 'r') as zip:\n",
        "      # storing all the contents of the zip file\n",
        "        zipped_files = zip.namelist()\n",
        "        # extracting only the pdb to a folder\n",
        "        for pdbfile in zipped_files:\n",
        "          if(pdbfile[-4:]==\".pdb\"):\n",
        "            print(pdbfile)\n",
        "            zip.extract(pdbfile,\"/content/drive/MyDrive/Extracted_PDBs\")\n",
        "            break\n",
        "    zip.close()\n",
        "      \n"
      ],
      "metadata": {
        "id": "Tbg2zujQdxTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068e19f1-da37-4459-eb0d-88d4153941d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_46b15_unrelaxed_rank_1_model_1.pdb\n",
            "test_f7da8_unrelaxed_rank_1_model_1.pdb\n",
            "test_85408_unrelaxed_rank_1_model_1.pdb\n",
            "test_d65b5_unrelaxed_rank_1_model_1.pdb\n",
            "test_35045_unrelaxed_rank_1_model_1.pdb\n",
            "test_342b4_unrelaxed_rank_1_model_1.pdb\n",
            "test_f0c24_unrelaxed_rank_1_model_1.pdb\n",
            "test_36d17_unrelaxed_rank_1_model_1.pdb\n",
            "test_c0e83_unrelaxed_rank_1_model_1.pdb\n",
            "test_9efd6_unrelaxed_rank_1_model_1.pdb\n",
            "test_9a340_unrelaxed_rank_1_model_1.pdb\n",
            "test_9e089_unrelaxed_rank_1_model_1.pdb\n",
            "test_f6e3a_unrelaxed_rank_1_model_1.pdb\n",
            "test_fb06a_unrelaxed_rank_1_model_1.pdb\n",
            "test_04206_unrelaxed_rank_1_model_1.pdb\n",
            "test_e12c8_unrelaxed_rank_1_model_1.pdb\n",
            "test_69d4b_unrelaxed_rank_1_model_1.pdb\n",
            "test_c77b9_unrelaxed_rank_1_model_1.pdb\n",
            "test_90296_unrelaxed_rank_1_model_1.pdb\n",
            "test_b667c_unrelaxed_rank_1_model_1.pdb\n",
            "test_2ff52_unrelaxed_rank_1_model_1.pdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def preprocess_to_feature_input(filename):\n",
        "  with open (filename, \"r\") as myfile:\n",
        "    data = myfile.read().splitlines()\n",
        "    \n",
        "  unique_atoms = np.unique([i.split()[0] for i in data] + [i.split()[1] for i in data])\n",
        "  atoms2id ={i:ind for ind, i in enumerate(unique_atoms)}\n",
        "  atoms2id\n",
        "  id2atoms = {ind:i for ind, i in enumerate(unique_atoms)}\n",
        "  deg_temp = np.unique([i.split()[0] for i in data] + [i.split()[1] for i in data], return_counts = True)\n",
        "  atom_degree = {atoms2id[deg_temp[0][i]]:deg_temp[1][i] for i in range(len(deg_temp[0]))}\n",
        "  edges = [[atoms2id[i.split()[0]], atoms2id[i.split()[1]]] for i in data]\n",
        "  bond_length = {str(atoms2id[i.split()[0]])+\"_\" + str(atoms2id[i.split()[1]]):float(i.split()[5][:-1]) for i in data}\n",
        "  id2atomName = {atoms2id[i]: i.split(\":\")[-1] for i in atoms2id}\n",
        "\n",
        "  res = {\"edges\": edges, \"features_degree\": atom_degree, \"bond_length\" : bond_length, \"atomName\":id2atomName, \"id2atoms\":id2atoms}\n",
        "  np.save(f\"{filename[:-4]}_out.npy\", res)\n",
        "\n",
        "  return res\n",
        "  \n"
      ],
      "metadata": {
        "id": "tZG6np-sBf3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = str(file)\n",
        "x[-16:-11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tho1e52xnuYC",
        "outputId": "6f51c804-076d-437c-bccf-a946e1a3fa76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2ff52'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x7dcvuzA2HcI",
        "outputId": "9019482a-908a-440b-9d46-5721e5f80c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.7/dist-packages (from graphein) (0.6.0)\n",
            "Collecting pyyaml<6.*,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 58.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from graphein) (4.64.1)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.7/dist-packages (from graphein) (0.20.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from graphein) (1.0.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from graphein) (1.10.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from graphein) (4.1.1)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting bioservices>=1.10.0\n",
            "  Downloading bioservices-1.10.4.tar.gz (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 68.7 MB/s \n",
            "\u001b[?25hCollecting deepdiff\n",
            "  Downloading deepdiff-6.2.1-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from graphein) (1.3.5)\n",
            "Collecting biopandas>=0.4.1\n",
            "  Downloading biopandas-0.4.1-py2.py3-none-any.whl (878 kB)\n",
            "\u001b[K     |████████████████████████████████| 878 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from graphein) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from graphein) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from graphein) (1.21.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from graphein) (2.6.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from graphein) (0.11.2)\n",
            "Collecting rich\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 72.5 MB/s \n",
            "\u001b[?25hCollecting biopython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 70.4 MB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting matplotlib>=3.4.3\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 50.2 MB/s \n",
            "\u001b[?25hCollecting rich-click\n",
            "  Downloading rich_click-1.5.2-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from biopandas>=0.4.1->graphein) (57.4.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from bioservices>=1.10.0->graphein) (1.4.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bioservices>=1.10.0->graphein) (4.6.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting easydev>=0.12.0\n",
            "  Downloading easydev-0.12.0.tar.gz (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting grequests\n",
            "  Downloading grequests-0.6.0-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bioservices>=1.10.0->graphein) (2.23.0)\n",
            "Collecting requests_cache\n",
            "  Downloading requests_cache-0.9.7-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting suds-community>=0.7\n",
            "  Downloading suds_community-1.1.2-py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 65.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from bioservices>=1.10.0->graphein) (4.9.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from bioservices>=1.10.0->graphein) (1.14.1)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from easydev>=0.12.0->bioservices>=1.10.0->graphein) (4.8.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.3->graphein) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.3->graphein) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.3->graphein) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.3->graphein) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.3->graphein) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.3->graphein) (21.3)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 53.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->graphein) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.3->graphein) (1.15.0)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting gevent\n",
            "  Downloading gevent-22.10.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gevent->grequests->bioservices>=1.10.0->graphein) (2.0.1)\n",
            "Collecting zope.event\n",
            "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-5.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->easydev>=0.12.0->bioservices>=1.10.0->graphein) (0.7.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->graphein) (8.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bioservices>=1.10.0->graphein) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bioservices>=1.10.0->graphein) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bioservices>=1.10.0->graphein) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bioservices>=1.10.0->graphein) (3.0.4)\n",
            "Collecting url-normalize>=1.4\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting cattrs>=22.2\n",
            "  Downloading cattrs-22.2.0-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.7/dist-packages (from requests_cache->bioservices>=1.10.0->graphein) (22.1.0)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 74.0 MB/s \n",
            "\u001b[?25hCollecting exceptiongroup\n",
            "  Downloading exceptiongroup-1.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->graphein) (2.6.1)\n",
            "Requirement already satisfied: click>=7 in /usr/local/lib/python3.7/dist-packages (from rich-click->graphein) (7.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rich-click->graphein) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rich-click->graphein) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->graphein) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->graphein) (3.1.0)\n",
            "Building wheels for collected packages: graphein, bioservices, easydev, wget\n",
            "  Building wheel for graphein (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphein: filename=graphein-1.5.2-py3-none-any.whl size=199493 sha256=a2486d9b57b5343993c243f457f091458b67731612fc451fdb9b614ac2053281\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/48/9a/0ddbe614546fd359396e4217c99dab08740f7ef46c77ce5cea\n",
            "  Building wheel for bioservices (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bioservices: filename=bioservices-1.10.4-py3-none-any.whl size=230589 sha256=608d295d39c82847f75f4bb05b32c79e99a24e4ddf4490ab62d5ab47840250ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/cb/d0/febd08b3daa26f7634f180b7dcc9393782ffe92d97c024ee34\n",
            "  Building wheel for easydev (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easydev: filename=easydev-0.12.0-py3-none-any.whl size=64231 sha256=5d95beadf60e5f8b446675772a42d1e5fb4d22c18954110e287a6f6377c6afd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/83/fdfc4017ea44a585b6754752cc5f63f2d0d63fcc1317e7174b\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=353e31aa8baebd3cdaec5204a19c1e5d38381e08dd55c1c48b58549c774542b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built graphein bioservices easydev wget\n",
            "Installing collected packages: zope.interface, zope.event, urllib3, exceptiongroup, url-normalize, gevent, fonttools, commonmark, colorlog, colorama, cattrs, xmltodict, suds-community, rich, requests-cache, ordered-set, matplotlib, grequests, easydev, wget, rich-click, pyyaml, loguru, deepdiff, bioservices, biopython, biopandas, graphein\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed biopandas-0.4.1 biopython-1.79 bioservices-1.10.4 cattrs-22.2.0 colorama-0.4.6 colorlog-6.7.0 commonmark-0.9.1 deepdiff-6.2.1 easydev-0.12.0 exceptiongroup-1.0.1 fonttools-4.38.0 gevent-22.10.2 graphein-1.5.2 grequests-0.6.0 loguru-0.6.0 matplotlib-3.5.3 ordered-set-4.1.0 pyyaml-5.4.1 requests-cache-0.9.7 rich-12.6.0 rich-click-1.5.2 suds-community-1.1.2 url-normalize-1.4.3 urllib3-1.25.11 wget-3.2 xmltodict-0.13.0 zope.event-4.5.0 zope.interface-5.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graphein.protein.graphs import construct_graph\n",
        "from graphein.protein.edges.atomic import add_atomic_edges\n",
        "from graphein.protein.config import ProteinGraphConfig\n",
        "import networkx as nx\n",
        "\n",
        "params_to_change = {\"granularity\": \"atom\", \"edge_construction_functions\": [add_atomic_edges]}\n",
        "\n",
        "config = ProteinGraphConfig(**params_to_change)\n",
        "config.dict()\n",
        "\n",
        "\n",
        "directory = '/content/drive/MyDrive/Extracted_PDBs'\n",
        " \n",
        "# iterate over files in that directory\n",
        "files = Path(directory).glob('*')\n",
        "for file in files:\n",
        "  # print(file)\n",
        "  if(str(file)[-4:]==\".pdb\"):\n",
        "    print(str(file)[-34:-29])\n",
        "    g = construct_graph(config=config, pdb_path=str(file))\n",
        "    txt_filename = 'pdb_text'+str(file)[-34:-29]+'.txt'\n",
        "    print(txt_filename)\n",
        "    nx.write_edgelist(g, txt_filename)\n",
        "    gh = preprocess_to_feature_input(txt_filename)\n",
        "    print(str(file)+\" Done\")"
      ],
      "metadata": {
        "id": "DskpFn5IyCT-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "97a3be84-5fe5-488f-ba31-d68cad04a7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-28b1360c3660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstruct_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_atomic_edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProteinGraphConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphein'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}